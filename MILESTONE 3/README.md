# ğŸ” AI Research Assistant

A comprehensive academic research assistant powered by **LangGraph**, **Groq AI**, and multiple academic APIs. Features a modern ChatGPT-like web interface for searching academic papers, uploading research documents for analysis, and generating detailed research reports with proper citations.

## âœ¨ Key Features

### ğŸŒ **Modern Web Interface**
- ChatGPT-inspired design with dark/light mode
- Chat history with rename, delete, and search
- Compact, aesthetic user interface
- Real-time markdown rendering
- Responsive mobile-friendly layout

### ğŸ“š **Academic Paper Search**
- **Semantic Scholar** integration for computer science papers
- **arXiv** integration for preprints and research papers
- Intelligent paper relevance ranking
- Automatic citation extraction and formatting
- APA-style reference generation

### ğŸ“„ **Document Upload & Analysis**
- Upload research papers (PDF, DOCX, TXT)
- Automatic text extraction and processing
- AI-powered summarization
- Topic extraction
- Reference/citation extraction
- Document authenticity verification (genuineness score)
- Ask questions about uploaded documents

### ğŸ¤– **LangGraph Multi-Agent Workflow**
- **Planner Agent**: Breaks down research queries into sub-tasks
- **Searcher Agent**: Searches academic databases and synthesizes findings
- **Writer Agent**: Creates comprehensive, well-cited reports
- **Conversational Memory**: Context-aware follow-up questions

### ğŸ’¬ **Advanced Chat Features**
- Persistent conversation history
- Multi-turn context awareness
- Markdown-formatted responses
- Copy and download reports
- Auto-rename chats based on content

---

## ğŸš€ Quick Start

### Prerequisites
- Python 3.8+
- Groq API key (free tier available)
- Internet connection

### 1. Installation

```bash
cd "MILESTONE 3"
pip install -r requirements.txt
```

### 2. Environment Setup

Create a `.env` file in the project root:

```env
GROQ_API_KEY=your_groq_api_key_here
```

**Get your Groq API key**: https://console.groq.com/keys

### 3. Run the Application

```bash
python app.py
```

Then open your browser to: **http://localhost:5000**

---

## ğŸ“ Project Structure

```
MILESTONE 3/
â”œâ”€â”€ app.py                          # Flask web server & API endpoints
â”œâ”€â”€ database.py                     # SQLite database operations
â”œâ”€â”€ document_processor.py           # Document upload & processing
â”œâ”€â”€ academic_orchestrator.py        # LangGraph workflow coordinator
â”œâ”€â”€ workflow.py                     # LangGraph state graph definition
â”œâ”€â”€ models.py                       # Pydantic data models
â”‚
â”œâ”€â”€ planner_agent/
â”‚   â”œâ”€â”€ agent.py                   # Research planning agent
â”‚   â””â”€â”€ prompts.py                 # Planning prompts
â”‚
â”œâ”€â”€ searcher_agent/
â”‚   â”œâ”€â”€ academic_agent.py          # Academic paper search
â”‚   â”œâ”€â”€ agent.py                   # Web search agent
â”‚   â””â”€â”€ prompts.py                 # Search prompts
â”‚
â”œâ”€â”€ writer_agent/
â”‚   â”œâ”€â”€ agent.py                   # Report writing agent
â”‚   â””â”€â”€ prompts.py                 # Writing prompts
â”‚
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index_v2.html              # Web interface
â”‚
â”œâ”€â”€ static/
â”‚   â”œâ”€â”€ style_v2.css               # Styling
â”‚   â””â”€â”€ script_v2.js               # Frontend logic
â”‚
â”œâ”€â”€ uploads/                        # Uploaded documents (auto-created)
â”œâ”€â”€ research.db                     # SQLite database (auto-created)
â”œâ”€â”€ requirements.txt                # Python dependencies
â”œâ”€â”€ .env                           # Environment variables (create this)
â””â”€â”€ README.md                      # This file
```

---

## ğŸ¯ How It Works

### Academic Paper Search Mode

When **no documents** are uploaded:

```
User Query
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Planner Agent          â”‚ â†’ Breaks query into 3 research sub-tasks
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Academic Searcher      â”‚ â†’ Searches Semantic Scholar & arXiv
â”‚  (runs for each task)   â”‚   Ranks papers by relevance
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Writer Agent           â”‚ â†’ Synthesizes findings into report
â”‚                         â”‚   Adds proper citations
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
Comprehensive Research Report (Markdown)
```

### Document Analysis Mode

When documents **are uploaded**:

```
User uploads PDF/DOCX
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Document Processor     â”‚ â†’ Extracts text
â”‚                         â”‚   Generates summary
â”‚                         â”‚   Verifies genuineness
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
User asks question
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Direct Analysis        â”‚ â†’ Analyzes uploaded document
â”‚  (Groq LLM)             â”‚   Answers from document content
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
Document-based Answer
```

---

## ğŸ’» Usage Examples

### Web Interface

1. **Start the server**: `python app.py`
2. **Open browser**: http://localhost:5000
3. **Ask a question**: "What are the latest developments in quantum computing?"
4. **Upload a document**: Click ğŸ“ â†’ Select PDF/DOCX â†’ Ask questions about it
5. **View chat history**: Sidebar shows all your research sessions

### Programmatic Usage

```python
from dotenv import load_dotenv
from langchain_groq import ChatGroq
from academic_orchestrator import AcademicResearchOrchestrator
import os

load_dotenv()

# Initialize LLM
llm = ChatGroq(
    model="llama-3.3-70b-versatile",
    temperature=0.7,
    groq_api_key=os.getenv("GROQ_API_KEY")
)

# Create orchestrator
orchestrator = AcademicResearchOrchestrator(llm)

# Perform research
report, papers = orchestrator.research(
    "What are transformer models in NLP?",
    verbose=True
)

print(f"Found {len(papers)} papers")
print(report)
```

### Document Processing

```python
from document_processor import DocumentProcessor
from langchain_groq import ChatGroq

llm = ChatGroq(model="llama-3.3-70b-versatile")
processor = DocumentProcessor(llm)

# Process a document
result = processor.process_document("path/to/paper.pdf")

print(f"Summary: {result['summary']}")
print(f"Word count: {result['word_count']}")
print(f"Genuineness score: {result['genuineness']['score']}/10")
```

---

## ğŸ”§ Configuration

### Environment Variables

| Variable | Required | Description |
|----------|----------|-------------|
| `GROQ_API_KEY` | **Yes** | Groq API key for LLM inference |

### Supported File Types

- **PDF**: Research papers, articles
- **DOCX**: Microsoft Word documents
- **TXT**: Plain text files

**Maximum file size**: 20MB

---

## ğŸ“Š API Endpoints

### Chat Management

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/chat/new` | POST | Create new chat |
| `/api/chat/list` | GET | Get all chats |
| `/api/chat/<id>` | GET | Get chat details |
| `/api/chat/<id>/rename` | PUT | Rename chat |
| `/api/chat/<id>` | DELETE | Delete chat |

### Research

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/chat/<id>/research` | POST | Perform research query |

### Document Management

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/chat/<id>/upload` | POST | Upload document |
| `/api/chat/<id>/documents` | GET | List documents |
| `/api/document/<id>` | GET | Get document details |
| `/api/document/<id>` | DELETE | Delete document |

---

## ğŸŒŸ Example Queries

### Academic Research
- "What are the latest breakthroughs in quantum computing in 2024?"
- "How is climate change affecting global food security?"
- "What are transformer models in natural language processing?"
- "Recent advances in CRISPR gene editing techniques"

### Document Analysis (after uploading)
- "Summarize this paper in 10 sentences"
- "What are the main topics discussed?"
- "Extract all cited references"
- "Is this research paper genuine?"
- "What methodology was used?"

---

## ğŸ› ï¸ Tech Stack

### Backend
- **Flask** - Web framework
- **LangGraph** - Multi-agent workflow orchestration
- **LangChain** - LLM framework
- **Groq** - Fast LLM inference (Llama 3.3 70B)
- **SQLite** - Lightweight database
- **PyPDF2** - PDF text extraction
- **python-docx** - DOCX text extraction

### Frontend
- **Vanilla JavaScript** - No frameworks, fast and simple
- **Marked.js** - Markdown rendering
- **CSS Variables** - Dynamic theming

### APIs
- **Semantic Scholar** - Academic paper search
- **arXiv** - Preprint repository

---

## ğŸ“ Features in Detail

### ğŸ¨ UI/UX Highlights
- **Compact design**: Small chatbox, optimized spacing
- **Document upload**: ChatGPT-style paperclip button
- **Theme toggle**: Seamless dark/light mode switching
- **Auto-resize textarea**: Grows with input
- **Markdown rendering**: Rich formatting for reports
- **Copy/Download**: Save reports easily

### ğŸ”¬ Research Workflow
1. **Query decomposition**: Breaks complex questions into focused sub-tasks
2. **Parallel search**: Searches multiple academic databases
3. **Relevance ranking**: Prioritizes most relevant papers
4. **Citation extraction**: Automatically formats references
5. **Synthesis**: Combines findings into cohesive narrative

### ğŸ“„ Document Intelligence
- **Text extraction**: Multi-format support
- **Smart summarization**: AI-generated overviews
- **Genuineness scoring**: 1-10 authenticity rating
- **Topic analysis**: Automatic subject extraction
- **Reference extraction**: Finds citations in text

---

## ğŸ› Troubleshooting

### Server won't start
- Check if port 5000 is available
- Verify `.env` file exists with `GROQ_API_KEY`
- Ensure all dependencies are installed

### "Can't reach this page"
- Make sure server is running (`python app.py`)
- Try http://127.0.0.1:5000 instead of localhost

### Document upload fails
- File must be PDF, DOCX, or TXT
- Maximum file size is 20MB
- Check file isn't corrupted

### No research results
- Verify internet connection
- Check Groq API key is valid
- Academic APIs may be temporarily unavailable

---

## ğŸ“š Dependencies

Key Python packages:
- `flask` - Web server
- `langchain` - LLM framework
- `langchain-groq` - Groq integration
- `langgraph` - Workflow graphs
- `PyPDF2` - PDF processing
- `python-docx` - Word docs
- `python-magic-bin` - File type detection
- `requests` - HTTP client
- `python-dotenv` - Environment variables

See `requirements.txt` for complete list.

---

## ğŸ“ Educational Purpose

This project was developed for academic coursework to demonstrate:
- Multi-agent AI systems
- LangGraph workflow design
- Academic research automation
- Document processing pipelines
- Web application development
- API integration

---

## ğŸ“„ License

Educational project for college coursework. Feel free to learn from and extend the code.

---

## ğŸ™ Acknowledgments

- **Groq** - Fast LLM inference
- **LangChain** - Framework and tools
- **Semantic Scholar** - Academic paper API
- **arXiv** - Research paper repository

---

**Built with â¤ï¸ for academic research automation**
